# hmm

A script for solving the three initial problems of Hiden Markov Models

- The evaluation problem (Forward algorithm, Backward algorithm) - what is the probability that the observations are generated by the model?
- The decoding problem (Viterbi algorithm) - what is the most likely state sequence in the model that produced the observations?
- The learning problem (Baum-Welch algorithm) - how should we adjust the model parameters A, B and Pi in order to maximize the probability?

## Demo

A sample example is included basing on this [article]. Be aware that some models may produce errors in computations (e.g. division by zero) thus they need to be adjusted.

[article]: <https://en.wikipedia.org/wiki/Viterbi_algorithm>
